\documentclass[11pt,letterpaper]{paper}

% \usepackage{graphicx}
% \usepackage[outdir=./]{epstopdf}
% \usepackage{subfig}
\usepackage{natbib}

% Commands for font following JSS style conventions.
\newcommand{\pkg}[1]{{\normalfont\fontseries{b}\selectfont #1}}
\let\proglang=\textsf
\let\code=\texttt
\let\fct=\texttt

\usepackage{listings}
\usepackage{textcomp}
\usepackage{color}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{ %
  language=R,                     % the language of the code
  basicstyle=\footnotesize,       % the size of the fonts that are used for the code
  numbers=left,                   % where to put the line-numbers
  numberstyle=\tiny\color{gray},  % the style that is used for the line-numbers
  stepnumber=1,                   % the step between two line-numbers. If it's 1, each line
                                  % will be numbered
  numbersep=5pt,                  % how far the line-numbers are from the code
  backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
  showspaces=false,               % show spaces adding particular underscores
  showstringspaces=false,         % underline spaces within strings
  showtabs=false,                 % show tabs within strings adding particular underscores
  frame=single,                   % adds a frame around the code
  rulecolor=\color{black},        % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. commens (green here))
  tabsize=2,                      % sets default tabsize to 2 spaces
  captionpos=b,                   % sets the caption-position to bottom
  breaklines=true,                % sets automatic line breaking
  breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
  title=\lstname,                 % show the filename of files included with \lstinputlisting;
                                  % also try caption instead of title
  keywordstyle=\color{blue},      % keyword style
  commentstyle=\color{dkgreen},   % comment style
  stringstyle=\color{mauve},      % string literal style
  escapeinside={\%*}{*)},         % if you want to add a comment within your code
  morekeywords={*,...}            % if you want to add more keywords to the set
} 

\begin{document}



\vspace{2.0in}


\begin{centering}

{\huge \it
Supplementary Material  \\
for \\
``The Fractionally Cointegrated Vector Autoregression Model in \proglang{R}'' \\
}

\vspace{0.5in}


{\huge \it
A.K.A.  \\
``The pieces that landed on the cutting room floo\proglang{R}'' \\
}


\vspace{1.0in}

{\large 
Lealand Morin \\
{\it Department of Economics, University of Central Florida} \\
\medskip
Morten \O rregaard Nielsen\\
{\it Department of Economics, Queen's University and CREATES} \\
\medskip
Micha\l{} Ksawery Popiel\\
{\it Analysis Group} \\
}

\vspace{0.5in}


\today

\end{centering}

\vspace{0.5in}


\section{Review of Existing Software}

% 
An exhaustive listing of the R packages \citep{R} available for time series analysis were compiled in 
\citet{Hyndman2020}.
% \emph{CRAN Task View: Time Series Analysis} by Rob J Hyndman, 
% available at \verb|https://CRAN.R-project.org/view=TimeSeries|). 
% 
Among these, the packages most relevant to the FCVAR model are those related to cointegration within the family of vector error correction models or those related to long memory, often under the $ARFIMA$ framework. 

% \subsection{R packages for estimating the CVAR model}


In \proglang{R}, contegration analysis can be conducted using a variety of packages. 
% 
One such package is \pkg{aTSA} for \emph{Alternative Time Series Analysis} \citep{aTSA2015}. 
In this package, the \fct{coint.test} function performs Engle-Granger tests, as in \citet{EngleGranger1987},  for the null hypothesis that two or more time series, each of which is I(1), are not cointegrated. 
This package is designed to focus on a particular response variable, restricting attention to relationships with a one-dimensional cointegrating space. That is, this framework can detect a single equilibrium equation. 
% 
Another package following the \citet{EngleGranger1987} approach is the \pkg{egcm} package in \citep{egcm2017}. 
The \pkg{egcm} package restricts to a simplified form of cointegration. 
It is designed for bivariate analysis, with a concentration on applications to the prices of financial assets.

Other packages have implemeted the cointegration tests in \citet{PhillipsOuliaris1990}. 
This amounts to running a regression of the response variable on a set of regressors and testing the residuals for a unit root following \cite{PhillipsPerron1988}. 
The \fct{po.test} from the \pkg{tseries} package \citep{tseries2019} implements this test, 
as well as the \fct{ca.po} function in the \pkg{urca} package \citep{urca2016}. 

The \pkg{cointReg} package in \cite{cointReg2016} follows a different approach, using modified ordinary least squares (OLS) approaches to the analysis of cointegration. 
One such method is the fully modified OLS (FM-OLS) approach of \citet{PhillipsHansen1990} in the \fct{cointRegFM} function. 
Another option is the dynamic OLS (D-OLS) approach (see \citet{PhillipsLoretan1991}, \citet{Saikkonen1991} and \citet{StockWatson1993}) implemented in \fct{cointRegD}. 
It also implements, in \fct{cointRegIM}, a variant called integrated modified OLS (IM-OLS) of Vogelsang and Wagner (2014), 
which is based on an augmented integration transformation of the regression model. 

Following another approach, 
\citet{Johansen1995} analyzes the cointegrated VAR model in a more holistic fashion.
In this framework, the time series are treated as an endogenous system of equations and permits the estimation of a higher-dimensional cointegrating relationship, i.e. several equilibrium relationships. 
% 
It also allows for the joint estimation of parameters relating to the system of equations, permitting likelihood ratio tests for a wide variety of hypotheses. 
The \fct{VECM} function in the \pkg{tsDyn} package allows for the application of either the \citet{EngleGranger1987} or the \citet{Johansen1995} MLE method. 
However, this package is designed primarily with nonlinear time series models in mind. 
The \pkg{urca} package \citep{urca2016}, 
which is designed to perform unit root tests and cointegration analysis, 
follows the \citet{Johansen1995} approach in the function \fct{ca.jo}. 
It also provides options for testing restrictions on the parameters in the model. 
Of the packages designed for the CVAR model, this is perhaps the closest available to the \pkg{FCVAR} package, in terms of the testing opportunities available.




% \subsection{Segue from CVAR to $I(d)$}

While the packages that follow the framework of \citet{Johansen1995} are most closely related to the \pkg{FCVAR} package, these are not suited to the analysis of series with a fractional degree of integration. 
That is to say that these packages allow for only a discrete form of cointegration between the series. 
For example, the series are all integrated, i.e. $I(1)$, and the residuals from a regression are stationary and $I(0)$. 
The fractionally cointegrated VAR model allows for the possibility that variables can be integrated of order $d$ and cointegrated of order $d - b$, where $d$ and $b>0$ can be real numbers. 
% 
Analysis using the above packages typically involves a preliminary analysis of the form of non-stationarity of the variables, using a number of unit root tests, i.e. to test whether the series are $I(1)$. 
With fractionally integrated variables, the first stage of the analysis is to determine the order of fractional integration, i.e. the parameter $d$. 
This has been the focus of much of the available software to analyze series with the characteristics of so-called long memory. 




% \subsection{R packages for fractional integration}

In another section of the \emph{CRAN Task View: Time Series Analysis} \citep{Hyndman2020}, 
several packages are listed for the estimation of models for series with features of fractional integration or long memory. 
A number of these pacakages are focused on estimation of $ARFIMA$ models, known as autoregressive fractionally integrated moving average models. 
The \pkg{fracdiff} package \citep{fracdiff2020} includes functions for fitting $ARFIMA(p,d,q)$ models, including the step of estimating the long memory parameter $d$. 
The namesake function \fct{fracdiff} calculates the maximum likelihood estimators of the parameters of a fractionally-differenced $ARIMA(p,d,q)$ model. 
A few notable functions in this package estimate the long memory parameter $d$ within this model\footnote{Note that the \fct{diffseries} function in \pkg{fracdiff} is based on the same algorithm in \cite{Jensen2014} as \fct{FracDiff} in \pkg{FCVAR}, except that \fct{diffseries} demeans the data first. Specifically, \code{fracdiff::diffseries(x, d) - FCVAR::FracDiff(x - mean(x), d)} is numerically very small. 
The demeaning step is not required to estimate the FCVAR model, as the mean parameters are estimated jointly with the others while optimizing the likelihood function. }. 
% 
The \pkg{arfima} package \cite{arfima2018} fits a wider variety of $ARFIMA$ models. 
% 
Also, the \pkg{nsarfima} \citep{nsarfima2019} package provides methods for fitting and simulating non-stationary $ARFIMA$ models. 
This package is more innovative in terms of the types of optimization problems built on the $ARFIMA$ model, including both maximum likelihood (as in \citet{Beran1995}) and minimum distance (as in \citet{Mayoral2007}) estimators. 
Overall, $ARFIMA$ models treat the data by fractional differencing to transform data to a form suitable for an $ARMA$ model, 
similar to ordinary first differencing for variables that have unit roots as in $ARIMA$ models. 
This transformation precludes the use of models that study cointegration relationships. 

The package \pkg{LongMemoryTS} is in a class of its own, in that it uses a wide variety of methods to investigate both fractional integration and cointegrating relationships.\footnote{Morten: You would be best suited to comment on the references in this package. 
There are several citations to your papers and papers that I'm sure you know better and I want to make sure that we are honest about the difference between what we do and what they do. 
It seems to me that this package is a who's who of analyzing the cointegration of fractional systems, except for Johansen's MLE framework, which is what we implement.
I like to think that our approach following \citet{Johansen1995} is more holistic, in that all the parameters are estimated jointly, aside from the rank and lag selection. 
It captures all of the pieces in one maximum likelihood framework and this approach has the added benefit of allowing for a wide range of restrictions to test. 

\textbf{Before I forget}, one important point to note is that I did not succeed in installing this package. 
It requires dependencies that would not install on either my local machine or the ones in Dunning 211 or the equivalent at UCF. 
I'm a patient guy but if I can't get it to work in 10 minutes, their user base is going to be very small. 
That's too bad, because they have also implemented \cite{Jensen2014}, with your permission, in the function \fct{fdiff}. I would have liked to test it for myself. 
In my opinion, they have too much going on in one package and the level of complexity can lead to dependency problems like this. 
As a user, I would move on to the next package that works, which is a good reason to implement this function ourselves, without these problems. 
Actually, now that I have looked at it more closely, the documentation is incomplete as well. 
Our closest competitor is a work in progress -- but there is no need to call them out on it. } 
% 
For estimating the order of the fractional integration in a series, there are several options including the log-periodogram estimators of \citet{GPH1983} and \citet{RobinsonPM1995b}. 
% 
Other options include the semiparametric local Whittle estimator of \citet{RobinsonPM1995a},
the exact local Whittle estimator of \citet{ShimotsuPhillips2005}, 
and a version for series with unknown mean and time trend in \citet{Shimotsu2010}. 
They also implement more recent approaches, such as 
the local polynomial Whittle plus noise estimator of \citet{FredNielsenNielsen2012} 
and the modified local Whittle estimator of \citet{HouPerron2014}. 


For determining the cointegrating rank, i.e. the dimension of the cointegrating relationship, this package also provides several options. 
These inclide a semiparametric method in \citet{ChenHurvich2003}. 
\citet{RobinsonYajima2002} propose a model selection procedure to estimate the cointegrating rank ,
which includes a test for equality of all memory parameters simultaneously and is further explored in \citet{NielsenShimotsu2007}. 
Following another approach, the package also provides a method of
identifying cointegration by eigenanalysis \citep{ZhangRobinsonYao2018}. 


Finally, for estimation the cointegrating relationship itself, the \pkg{LongMemoryTS} package implements a number of approaches. 
It implements semiparametric approaches for estimating the cointegrating vector, including that of 
\citet{Robinson1994} and later \citet{RobinsonMarinucci2003} and \citet{ChristensenNielsen2006}. 
They implement a semiparametric residual-based test for fractional cointegration from \citet{ChenHurvich2006}, 
and other semiparametric tests in \citet{MarmolVelasco2004}and \citet{WangWangChan2015}
and a semiparametric Hausmann-type test for fractional cointegration by \citet{Robinson2008}. 
Also within the semiparametric family is the fully modified narrow band least squares (FMNBLS) approach in  \citet{NielsenFrederiksen2011}. 
% 
They also implement a nonparametric approach to test for fractional cointegration and rank estimation by \citet{Nielsen2010}.
Following another framework, the frequency-domain test for fractional cointegration in \citet{SouzaEtal2018} is also available in this package. 

In contrast, our approach is to use a fully parametric model in the maximum likelihood framework. 
The \pkg{FCVAR} package, introduced here, is closest to a cross between the \citet{Johansen1995} cointegration model in \pkg{urca} and the models involving fractionally integrated variables discussed above. 
In particular, the model estimated in the \pkg{urca} packages is the special case of \pkg{FCVAR} in which the fractional integration parameters $d$ and $b$ are both equal to one.\footnote{They also use the Danish data, so it might be worthwhile to include in the documentation an example with and without the restriction $d = b = 1$ to compare. It may not fit in this paper but could be a short vignette (short pdf with code and descriptions) that would go on the CRAN webpage for the package. } 
% 
% 
% \subsection{The  MATLAB program}
% 
The \proglang{R} package \pkg{FCVAR} closely follows a companion package \pkg{FCVARmodel.m}, written in \proglang{MATLAB}. 
The \proglang{MATLAB} package is documented in \cite{Nielsen2016}, an expanded version of the package documented in \cite{Nielsen2013}. 



\section{Extended Description of Estimation Options}

\textbf{This material appears in the package documentation. 
The description in the paper includes only the chosen options relating to the model that is estimated. } \\


Once the data is imported, the user sets the program options. The script contains two sets of options: variables set for function arguments in the script itself and model/estimation related options. 
% Listing ~\ref{intl} shows the first of set of options. 
The first of set of options is as follows. 
% 
% NOTE: Alignment is achieved by counting the number of characters, including spaces.
% That is, this table looks ragged here but aligned in the document:
%\begin{Code}
\begin{lstlisting}[frame=single,caption={Initialization of local variables}, label = intl]
p               <- ncol(x1) 
kmax            <- 3
order           <- 12
printWNtest     <-  1
\end{lstlisting}
%\end{Code}

The variable \verb|kmax| determines the highest lag order for the sequential testing that is performed in the lag selection, whereas \verb|p| is the dimension of the system. 
% The other variables are self-explanatory.
The \verb|order| specifies the number of lags used for the white noise test in lag selection, 
while \verb|printWNtest| indicates whether to print results of white noise tests post-estimation. 


The next set of initialization commands
% , shown in Listing~\ref{intl2}, 
assign values to the variables contained in the object \verb|opt| defined by the function \fct{FCVARoptions}. 

%\begin{leftbar} 
%I wonder if we should leave some of this to the package documentation. 
%Maybe for this article, we should concentrate on the options that are necessary for the examples below. 
%Besides, JSS style prefers code blocks do not have comments, i.e. state it in the text. 
%We could say that ``the rest of the options are described in the package documentation''. 
% 
%Verdict: Here is a trimmed-down version. 
%I hope JSS is flexible about the comments, which I think are justified here.
%\end{leftbar}

% \begin{Code}
\begin{lstlisting}[frame=single,caption={Choosing estimation options}, label = intl2]
# Define variable to store estimation options.
opt              <- FCVARoptions() 
opt$dbMin        <- c(0.01, 0.01) # lower bound for d, b.
opt$dbMax        <- c(2.00, 2.00) # upper bound for d, b.
opt$unrConstant  <- 0   # include an unrestricted constant? 
opt$rConstant    <- 0   # include a restricted constant? 
opt$levelParam   <- 1   # include level parameter? 
opt$constrained  <- 0   # impose restriction dbMax >= d >= b >= dbMin? 
opt$restrictDB   <- 1   # impose restriction d = b ? 
opt$db0          <- c(0.80, 0.80) # set starting values for optimization.
opt$N            <- 0   # number of initial values to condition upon.
opt$print2screen <- 1   # print output.
opt$printRoots   <- 1   # do not print roots of characteristic polynomial.
opt$plotRoots    <- 1   # do not plot roots of characteristic polynomial.
opt$gridSearch   <- 1   # For more accurate estimation, perform a grid search.
                        # This will make estimation take longer.
opt$plotLike     <- 0   # Plot the likelihood (if gridSearch <- 1).
opt$progress     <- 0   # Show grid search progress indicator waitbar.
opt$updateTime   <- 0.5 # How often progress is updated (seconds).

# Store the options to reset them in between hypothesis tests.
DefaultOpt <- opt 
% \end{Code}
\end{lstlisting}

The first line initializes the object \verb|opt| and assigns all of the default options set in \verb|FCVARoptions|. 
The user can see the full set of options by typing \verb|DefaultOpt| (or \verb|opt| after initialization) in the command line. % Listing~\ref{intl2} 
The code block above 
shows how to easily change any of the default options. Defining the program options in this way allows the user to create and store several option objects with different attributes. This can be very convenient when, for example, performing the same hypothesis tests on different data sets. 

The set of available options can be broken into several categories: numerical optimization, model deterministics and restrictions, output and grid search.
% , and $p$~values for the rank test. 
% These are obtained internally from the \pkg{fracdist} package, with no user input. 
We recommend that only advanced users make changes to the numerical optimization options. Adding deterministics requires setting the variable corresponding to the type of deterministic component to 1. For instance, in the present example, a model estimated with options \verb|opt| will include the level parameter $\mu$ but no restricted or unrestricted constant. Output variables refer to either printing or plotting various information post-estimation and usually take values $1$ or $0$ (on or off). For example, if the user is not interested in the estimates of $\Gamma$, they can be suppressed by setting \verb|opt$printGammas <- 0|.

The bounds on the parameter space for $d$ and $b$ are specified in \verb|opt$dbMin| and \verb|opt$dbMax|. In this example, these are both specified as 2-dimensional column vectors, in which case the first element specifies the bound on $d$ and the second element the bound on $b$. Alternatively, one can set \verb|opt$dbMin| and \verb|opt$dbMax| as scalars, which imposes the same bounds on $d$ and $b$. 

An important feature in this package is the ability to pre-estimate by using a grid search. If the user selects this option, they can view progress by setting \verb|opt$progress| to $1$ (waitbar) or $2$ (output in command line). The minimum frequency of these updates is set by \verb|opt$updateTime|. The user also has the option (\verb|opt$plotLike|) to view a plot of the likelihood over $d$ and/or $b$ after the grid search completes. The output of the grid search is a preliminary estimate of the fractional parameters. These are used as starting values in the subsequent numerical optimization, and the bounds on $d$ and $b$ are set to these starting values plus/minus $0.1$ but still within the original \verb|dbMin| and \verb|dbMax| settings. \\

\textbf{Warning: }
The current package does not have the following functionality. 
It could be implemented but I imagine there already exists something in R that can serve this role. 
However, I think I don't quite understand the problem without it. 
Can you provide an example? \\

\textbf{Solution: }
You explained it and I added an example that uses this functionality.
I think the numerical example also makes the calculation of restrictions more concrete.  \\

As of v.1.4.0, the new option \verb|opt$LocalMax| allows more control over the grid search. If \verb|opt$LocalMax <- 0|, the function \fct{FCVARlikeGrid} returns the parameter values corresponding to the global maximum of the likelihood on the grid. If \verb|opt$LocalMax <- 1|, then \fct{FCVARlikeGrid} returns the parameter values for the local maximum corresponding to the highest value of $b$. This is meant to alleviate the identification problem discussed in \citet[Section 2.3]{johniel2010} and \cite{Carlini2014}. As of v.1.4.0, the default setting is \verb|opt$LocalMax <- 1|.

Another option is the addition of a line search to the switching algorithm for estimation of models with restrictions on $\alpha$ and/or $\beta$. This is added via the option \verb|opt$LineSearch <- 1| and is the default. See \citet[Section 2.2]{Doornik2016} for details.

%\begin{leftbar}
%Removing this to reflect our updated strategy for the $p$~values for cointegration rank tests
%-- it simply calls the \pkg{fracdist} package and calculates the $p$~values. 
%This is much better than calling the \pkg{Rcpp} package because it avoids the inevitable probelms with platform, compiler and software dependencies. 
%Besides, CRAN doesn't like packages to make system calls because it makes assumptions about the user's setup and leads to the above problems with dependencies. 
%\end{leftbar}
%
%In order to automatically obtain $p$~values for cointegration rank tests when $b>0.5$, the user needs to download and install the necessary program 
%% (see Section~\ref{sec obtaining}). 
%(see Section~\ref{sec:fdpval}). 
%The last option, \verb|opt$progLoc|, identifies the location of that program.

After all options have been set, the last line 
% in Listing~\ref{intl2} 
stores them in \verb|DefaultOpt| so that the user can recall them at any point in the estimation. This is particularly useful if the user wants to change only a few options in between estimations.




\bibliography{references}
% \bibliographystyle{plain}
\bibliographystyle{cje}



\end{document}

